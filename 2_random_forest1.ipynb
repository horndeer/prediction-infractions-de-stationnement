{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420fed95",
   "metadata": {},
   "source": [
    "# Random forest 1\n",
    "\n",
    "Dans ce notebook on test notre premier regresseur, un random forest basique qui nous donnera une base de départ pour comparer les futures approches.\n",
    "\n",
    "On fait très peu de pré-processing, simplement une fenêtre géographique pour enlever quelques outliers en conservant + de 98% des données.\n",
    "\n",
    "Pour limiter le temps de calcul, on entraine uniquement sur les données qui ont un nombre significatif d'observations, dans un premier temps > 10 puis > 6.\n",
    "On entraine sur environ 30% puis 40% des données, ce qui est une grosse perte mais qui donne quand même de bon premiers résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c0541",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88387daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from utils import load_train_data\n",
    "from utils import spearman_corr, rmse\n",
    "from utils import geo_filter, total_count_filter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "x, y = load_train_data()\n",
    "\n",
    "kf = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    n_estimators=10,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "spearman_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "i=1\n",
    "for train_index, val_index in kf.split(x):\n",
    "    x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Sélection des données\n",
    "    geo_filter_mask = geo_filter(x_train)\n",
    "    print(f\"geo filter mask filtered {geo_filter_mask.sum() /len(x_train):.2%} of data\")\n",
    "    total_count_filter_mask = total_count_filter(x_train, n_min=10)\n",
    "    print(f\"total count filter mask filtered {total_count_filter_mask.sum() / len(x_train):.2%} of data\")\n",
    "    filter_mask = geo_filter_mask & total_count_filter_mask\n",
    "    print(f\"Au total: {filter_mask.sum() / len(x_train):.2%} des données conservées.\")\n",
    "    \n",
    "    x_train = x_train[filter_mask]\n",
    "    y_train = y_train[filter_mask]\n",
    "    model.fit(x_train, y_train.values.flatten())\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "    \n",
    "    spearman_scores.append(spearman_corr(y_val.values.flatten(), y_pred))\n",
    "    rmse_scores.append(rmse(y_val.values.flatten(), y_pred))\n",
    "    print(f\"Fold {i}:\\tspearman: {spearman_scores[-1]:.4f},\\trmse: {rmse_scores[-1]:.4f}\\n\")\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "print(f\"Score de corrélation de Spearman: {np.mean(spearman_scores):.4f}, std: {np.std(spearman_scores):.4f}\")\n",
    "print(f\"RMSE: {np.mean(rmse_scores):.4f}, std: {np.std(rmse_scores):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f11d4",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e7107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_train_data, load_test_data\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x_train, y_train = load_train_data()\n",
    "x_test = load_test_data()\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    n_estimators=10,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "filter_mask, ratio_filtered_data = filter_data(x_train, n_min=5, geo_filter=True)\n",
    "x_train = x_train[filter_mask]\n",
    "y_train = y_train[filter_mask]\n",
    "\n",
    "model.fit(x_train, y_train.values.flatten())\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred = pd.Series(y_pred, index=x_test.index, name=\"prediction\")\n",
    "y_pred.to_csv(\"output/y_pred_rdmforest2.csv\", index=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9af2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv(\"output/y_pred_rdmforest2.csv\", index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
